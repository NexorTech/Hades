from urllib.parse import urljoin, urlparse, parse_qs
from bs4 import BeautifulSoup
import requests
import re


def is_meaningful_response(response, injected_value, baseline_response):
    if injected_value in response.text:
        print("[+] Reflected value detected!")
        return True

    if abs(len(response.text) - len(baseline_response.text)) > 50:
        print("[+] Significant content size difference")
        return True

    if response.status_code != baseline_response.status_code:
        print("[+] Status code change detected")
        return True

    baseline_title = re.search(r"<title>(.*?)</title>", baseline_response.text, re.I)
    current_title = re.search(r"<title>(.*?)</title>", response.text, re.I)
    if baseline_title and current_title:
        if baseline_title.group(1).strip() != current_title.group(1).strip():
            print(f"[+] Title changed: {baseline_title.group(1)} -> {current_title.group(1)}")
            return True

    if "<form" in response.text and "<form" not in baseline_response.text:
        print("[+] New form appeared")
        return True

    if "<table" in response.text and "<table" not in baseline_response.text:
        print("[+] New table appeared")
        return True

    if response.url != baseline_response.url:
        print(f"[+] Redirect detected: {response.url}")
        return True

    error_keywords = ["error", "exception", "invalid", "syntax", "SQL"]
    for keyword in error_keywords:
        if keyword.lower() in response.text.lower() and keyword.lower() not in baseline_response.text.lower():
            print(f"[+] Error keyword: {keyword}")
            return True

    return False


def smart_query_param_finder(base_url):
    visited = set()
    to_visit = [base_url]
    found_params = set()

    headers = {
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    while to_visit:
        url = to_visit.pop()
        norm_url = url.split('#')[0]  # Remove fragment
        if norm_url in visited:
            continue
        visited.add(norm_url)

        try:
            r = requests.get(url, headers=headers, timeout=5)
        except:
            continue

        soup = BeautifulSoup(r.text, 'html.parser')

        for a in soup.find_all('a', href=True):
            link = urljoin(url, a['href'])
            link = link.split('#')[0]  # Normalize
            parsed = urlparse(link)

            qs = parse_qs(parsed.query)
            for param in qs.keys():
                found_params.add(param)

            # Queue more links to visit
            if link not in visited:
                to_visit.append(link)

        forms = soup.find_all('form')
        for form in forms:
            action = form.get('action') or url
            method = form.get('method', 'get').lower()
            inputs = form.find_all(['input', 'textarea', 'select', 'button'])

            data = {}
            for input_tag in inputs:
                name = input_tag.get('name')
                if name:
                    data[name] = 'test123'
                    found_params.add(name)

            selects = form.find_all('select')
            for select in selects:
                name = select.get('name')
                if name:
                    found_params.add(name)

            action_url = urljoin(url, action)
            baseline_response = requests.get(action_url, headers=headers)

            if method == 'get':
                response = requests.get(action_url, params=data, headers=headers)
            else:
                response = requests.post(action_url, data=data, headers=headers)

            is_meaningful_response(response, "test123", baseline_response)

    return sorted(found_params)


# url = input("Enter URL to find the query params: ")
# params = smart_query_param_finder(url)
# print("\n[+] Found query parameters / injectable fields:")
# print(params)
